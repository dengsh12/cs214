# consumer.py
import time
from confluent_kafka import Consumer, KafkaException
import utility

@utility.timer
def consume_messages(consumer_conf, topic, num_messages, log_interval, metrics_list=None, process_id=0):
    """
    æ¶ˆè´¹è€…æ¥æ”¶æ¶ˆæ¯ï¼Œè®¡ç®—å»¶è¿Ÿ
    :param consumer_conf: dict, Consumer é…ç½®ä¿¡æ¯
    :param topic: str, æ¶ˆè´¹çš„ Kafka Topic
    :param num_messages: int, æ¶ˆè´¹çš„æ¶ˆæ¯æ•°
    :param log_interval: int, æ—¥å¿—æ‰“å°é—´éš”
    :param metrics_list: Manager list, ç”¨äºå­˜æ”¾æŒ‡æ ‡æ•°æ®
    :param process_id: int, æ¶ˆè´¹è€…è¿›ç¨‹ç¼–å·
    :return: latencies listï¼ˆä»…ç”¨äºå†…éƒ¨ç»Ÿè®¡ï¼‰
    """
    consumer = Consumer(consumer_conf)
    consumer.subscribe([topic])
    latencies = []
    cold_start_latencies = []  # ç”¨äºå­˜æ”¾å‰ N æ¡æ¶ˆæ¯å»¶è¿Ÿ
    cold_start_count = 50  # å®šä¹‰å‰50æ¡æ¶ˆæ¯ä½œä¸ºå†·å¯åŠ¨è®¡ç®—
    count = 0
    start_time = time.time()
    t2latencies = {}

    while count < num_messages:
        if count % log_interval == 0:
            print(f"ğŸ”´ æ¶ˆè´¹è€…[{process_id}]æ¥æ”¶æ¶ˆæ¯: {count}/{num_messages}")
        msg = consumer.poll(timeout=5.0)
        if msg is None:
            continue
        if msg.error():
            raise KafkaException(msg.error())
        current_time = time.time()
        try:
            value_str = msg.value().decode('utf-8')
            # å–æ¶ˆæ¯ä¸­ "|" å‰é¢çš„éƒ¨åˆ†ä½œä¸ºæ—¶é—´æˆ³
            timestamp_str = value_str.split("|")[0]
            sent_time = float(timestamp_str)
        except Exception as e:
            print(f"ğŸ”´ æ¶ˆè´¹è€…[{process_id}]è§£ç æ¶ˆæ¯å¤±è´¥: {e}")
            continue
        latency = current_time - sent_time
        latencies.append(latency)
        if current_time in t2latencies.keys():
            t2latencies[current_time] = ((t2latencies[current_time][0] * t2latencies[current_time][1] + latency) / (t2latencies[current_time][1] + 1),
                                          t2latencies[current_time][1] + 1)
        else:
            t2latencies[current_time] = (latency, 1)
        
        if count < cold_start_count:
            cold_start_latencies.append(latency)
        count += 1

    consumer.close()
    end_time = time.time()
    duration = end_time - start_time
    throughput = num_messages / duration if duration > 0 else 0
    avg_latency = sum(latencies) / len(latencies) if latencies else 0
    sorted_latencies = sorted(latencies)
    p99_latency = sorted_latencies[int(len(sorted_latencies) * 0.99) - 1] if latencies and len(sorted_latencies) > 0 else 0
    max_latency = max(latencies) if latencies else 0
    # è®¡ç®—å†·å¯åŠ¨å»¶è¿Ÿä¸ºå‰ cold_start_count æ¡æ¶ˆæ¯çš„å¹³å‡å»¶è¿Ÿ
    cold_start_latency = sum(cold_start_latencies) / len(cold_start_latencies) if cold_start_latencies else 0
    metrics = {
        "process_id": process_id,
        "role": "consumer",
        "messages": num_messages,
        "duration": duration,
        "throughput": throughput,
        "avg_latency": avg_latency,
        "p99_latency": p99_latency,
        "max_latency": max_latency,
        "cold_start_latency": cold_start_latency,
        "t2latencies": t2latencies,
    }
    if metrics_list is not None:
        metrics_list.append(metrics)
    print(f"âœ… æ¶ˆè´¹è€…[{process_id}]å®Œæˆæ¥æ”¶æ¶ˆæ¯, è€—æ—¶: {duration:.6f} ç§’, ååé‡: {throughput:.2f} msg/s")
    return latencies
