# main.py
import time
from multiprocessing import Process, Manager
import argparse
from confluent_kafka.admin import AdminClient, NewTopic
from producer import produce_messages
from consumer import consume_messages
import utility

def delete_topic(admin_client, topic_name):
    """åˆ é™¤ Kafka ä¸»é¢˜"""
    print(f"å°è¯•åˆ é™¤ Topic: {topic_name}")
    topic_metadata = admin_client.list_topics(timeout=10)
    if topic_name not in topic_metadata.topics:
        print(f"Topic {topic_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆ é™¤")
        return
    fs = admin_client.delete_topics([topic_name], operation_timeout=30)
    for topic, f in fs.items():
        try:
            print(f"ç­‰å¾… Topic {topic} åˆ é™¤")
            f.result()  # é˜»å¡ç›´åˆ°åˆ é™¤å®Œæˆ
            print(f"âœ… Topic {topic} åˆ é™¤æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ Topic {topic} åˆ é™¤å¤±è´¥: {e}")
    print()
    while True:
        topic_metadata = admin_client.list_topics(timeout=10)
        if topic_name not in topic_metadata.topics:
            break
        print(f"âš ï¸ Topic {topic_name} ä»åœ¨åˆ é™¤ä¸­ï¼Œç­‰å¾…...")
    time.sleep(5)

def create_topic(admin_client, topic_name, num_partitions=3, replication_factor=1):
    """
    æ£€æŸ¥å¹¶åˆ›å»º Kafka ä¸»é¢˜ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡ã€‚
    """
    topic_metadata = admin_client.list_topics(timeout=10)
    if topic_name in topic_metadata.topics:
        print(f"âš ï¸ Topic {topic_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
        return

    print(f"ğŸš€ åˆ›å»º Topic: {topic_name}")
    topic_list = [NewTopic(topic_name, num_partitions=num_partitions, replication_factor=replication_factor)]
    fs = admin_client.create_topics(topic_list, operation_timeout=30)
    for t, f in fs.items():
        try:
            f.result()
            print(f"âœ… Topic {t} åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ Topic {t} åˆ›å»ºå¤±è´¥: {e}")
    print()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="MQ ååé‡ä¸å»¶è¿Ÿæµ‹è¯•")
    parser.add_argument("--mq_type", type=str, default="kafka", help="æ¶ˆæ¯é˜Ÿåˆ—ç±»å‹, kafka æˆ– rabbitmq")
    parser.add_argument("--broker_address", type=str, default="localhost:9092", help="Broker åœ°å€")
    parser.add_argument("--topic", type=str, default="test-throughput", help="æµ‹è¯• Topic åç§°")
    parser.add_argument("--num_producers", type=int, default=50, help="ç”Ÿäº§è€…æ•°é‡")
    parser.add_argument("--num_consumers", type=int, default=50, help="æ¶ˆè´¹è€…æ•°é‡")
    parser.add_argument("--messages_per_producer", type=int, default=1000, help="æ¯ä¸ªç”Ÿäº§è€…å‘é€çš„æ¶ˆæ¯æ•°é‡")
    parser.add_argument("--log_interval", type=int, default=100, help="æ—¥å¿—æ‰“å°é—´éš”")
    args = parser.parse_args()

    total_messages = args.num_producers * args.messages_per_producer
    messages_per_consumer = total_messages // args.num_consumers

    if args.mq_type.lower() == "kafka":
        admin_client = AdminClient({"bootstrap.servers": args.broker_address})
        delete_topic(admin_client, args.topic)
        # è®¾ç½®åˆ†åŒºæ•°ä¸ºæ¶ˆè´¹è€…æ•°é‡ï¼Œç¡®ä¿æ¯ä¸ªæ¶ˆè´¹è€…åˆ†åˆ°ä»»åŠ¡
        create_topic(admin_client, args.topic, num_partitions=args.num_consumers, replication_factor=1)
    else:
        print("ç›®å‰ä»…æ”¯æŒ Kafka, å…¶ä»– MQ éœ€è¦å®ç°å¯¹åº”é€‚é…å™¨")
        exit(1)

    manager = Manager()
    producer_metrics = manager.list()
    consumer_metrics = manager.list()
    processes = []

    # å¯åŠ¨æ¶ˆè´¹è€…è¿›ç¨‹ï¼ˆå…ˆå¯åŠ¨å¯æµ‹å†·å¯åŠ¨å»¶è¿Ÿï¼‰
    for i in range(args.num_consumers):
        p = Process(target=consume_messages, args=(
            {
                'bootstrap.servers': args.broker_address,
                'group.id': "latency-test-group",
                'auto.offset.reset': 'earliest'
            },
            args.topic, messages_per_consumer, args.log_interval, consumer_metrics, i
        ))
        p.start()
        processes.append(p)

    # å¯åŠ¨ç”Ÿäº§è€…è¿›ç¨‹
    for i in range(args.num_producers):
        p = Process(target=produce_messages, args=(
            {
                'bootstrap.servers': args.broker_address,
                'acks': 'all',
                'batch.size': 16384,
                'linger.ms': 5,
                'compression.type': 'lz4'
            },
            args.topic, args.messages_per_producer, args.log_interval, producer_metrics, i
        ))
        p.start()
        processes.append(p)

    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
    for p in processes:
        p.join()

    # æ±‡æ€»æŒ‡æ ‡
    total_messages_produced = sum(item["messages"] for item in producer_metrics)
    max_producer_duration = max(item["duration"] for item in producer_metrics) if producer_metrics else 1
    overall_throughput_producers = total_messages_produced / max_producer_duration

    avg_latency = sum(item["avg_latency"] for item in consumer_metrics) / len(consumer_metrics) if consumer_metrics else 0
    avg_p99_latency = sum(item["p99_latency"] for item in consumer_metrics) / len(consumer_metrics) if consumer_metrics else 0
    avg_cold_start = sum(item["cold_start_latency"] for item in consumer_metrics) / len(consumer_metrics) if consumer_metrics else 0

    avg_cpu_producers = sum(item["avg_cpu"] for item in producer_metrics) / len(producer_metrics) if producer_metrics else 0
    avg_mem_producers = sum(item["avg_mem"] for item in producer_metrics) / len(producer_metrics) if producer_metrics else 0
    avg_cpu_consumers = sum(item["avg_cpu"] for item in consumer_metrics) / len(consumer_metrics) if consumer_metrics else 0
    avg_mem_consumers = sum(item["avg_mem"] for item in consumer_metrics) / len(consumer_metrics) if consumer_metrics else 0

    print("\n===== ç»¼åˆæµ‹è¯•ç»“æœ =====")
    print(f"ç”Ÿäº§è€…: æ€»å‘é€æ¶ˆæ¯æ•°: {total_messages_produced}, å¹³å‡ååé‡: {overall_throughput_producers:.2f} msg/s")
    print("æ¶ˆè´¹è€…:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {avg_latency:.6f} s")
    print(f"  è¿‘ä¼¼99%å»¶è¿Ÿ: {avg_p99_latency:.6f} s")
    print(f"  å¹³å‡å†·å¯åŠ¨å»¶è¿Ÿ: {avg_cold_start:.6f} s")
    print("\nèµ„æºä½¿ç”¨æƒ…å†µ:")
    print(f"  ç”Ÿäº§è€… å¹³å‡ CPU: {avg_cpu_producers:.2f}%, å¹³å‡å†…å­˜: {avg_mem_producers/1024/1024:.2f} MB")
    print(f"  æ¶ˆè´¹è€… å¹³å‡ CPU: {avg_cpu_consumers:.2f}%, å¹³å‡å†…å­˜: {avg_mem_consumers/1024/1024:.2f} MB")
