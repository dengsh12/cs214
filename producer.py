# producer.py
import time
from confluent_kafka import Producer
import utility

@utility.timer
def produce_messages(producer_conf, topic, num_messages, log_interval, metrics_list=None, process_id=0):
    """
    ç”Ÿäº§è€…å‘é€å¸¦æœ‰æ—¶é—´æˆ³çš„æ¶ˆæ¯ï¼ŒåŒæ—¶ç›‘æ§èµ„æºä½¿ç”¨å’Œè®°å½•æŒ‡æ ‡
    :param producer_conf: dict, Producer é…ç½®ä¿¡æ¯
    :param topic: str, å‘é€åˆ°çš„ Kafka Topic
    :param num_messages: int, å‘é€çš„æ¶ˆæ¯æ•°
    :param log_interval: int, æ—¥å¿—æ‰“å°é—´éš”
    :param metrics_list: Manager list, ç”¨äºå­˜æ”¾æŒ‡æ ‡æ•°æ®
    :param process_id: int, ç”Ÿäº§è€…è¿›ç¨‹ç¼–å·
    """
    # å¼€å¯èµ„æºç›‘æ§
    samples, stop_event, monitor_thread = utility.resource_monitor()
    start_time = time.time()
    producer = Producer(producer_conf)

    for i in range(num_messages):
        if i % log_interval == 0:
            print(f"ğŸš€ ç”Ÿäº§è€…[{process_id}]å‘é€æ¶ˆæ¯: {i}/{num_messages}")
        timestamp = time.time()
        message_sent = False
        while not message_sent:
            try:
                # ç”¨ process_id-æ¶ˆæ¯åºå·ä½œä¸º keyï¼Œä¿è¯ä»¥åå¯ä»¥é€‚é…å…¶ä»– MQ æ—¶åšè·¯ç”±
                producer.produce(topic, key=f"{process_id}-{i}", value=str(timestamp))
                message_sent = True
            except BufferError:
                print(f"ğŸš€ ç”Ÿäº§è€…[{process_id}]é˜Ÿåˆ—å·²æ»¡ï¼Œç­‰å¾…...")
                producer.poll(1)

    producer.flush()
    end_time = time.time()
    duration = end_time - start_time
    throughput = num_messages / duration if duration > 0 else 0
    avg_cpu, avg_mem = utility.stop_resource_monitor(samples, stop_event, monitor_thread)
    metrics = {
        "process_id": process_id,
        "role": "producer",
        "messages": num_messages,
        "duration": duration,
        "throughput": throughput,
        "avg_cpu": avg_cpu,
        "avg_mem": avg_mem,
    }
    if metrics_list is not None:
        metrics_list.append(metrics)
    print(f"âœ… ç”Ÿäº§è€…[{process_id}]å®Œæˆæ¶ˆæ¯å‘é€, è€—æ—¶: {duration:.6f} ç§’, ååé‡: {throughput:.2f} msg/s")
